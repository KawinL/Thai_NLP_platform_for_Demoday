{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from bailarn.utils import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define tokenizer and word_embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bailarn.tokenizer import constant as tokenizer_constant\n",
    "from bailarn.tokenizer.tokenizer import Tokenizer\n",
    "\n",
    "# Create index for character and tag\n",
    "char_index = utils.build_tag_index(tokenizer_constant.CHARACTER_LIST, tokenizer_constant.CHAR_START_INDEX)\n",
    "tag_index = utils.build_tag_index(tokenizer_constant.TAG_LIST, tokenizer_constant.TAG_START_INDEX)\n",
    "\n",
    "tokenizer_model = Tokenizer(char_index, tag_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_func(sentence):\n",
    "    return tokenizer_model.predict(sentence)\n",
    "tokenize_func(\"ฉันกินข้าว\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bailarn.word_embedder.word2vec import Word2Vec\n",
    "w2v_model = Word2Vec()\n",
    "\n",
    "w2v_vocab = w2v_model.model.wv.vocab\n",
    "# example of w2v vocab\n",
    "sorted(w2v_vocab.items(), key=lambda x:x[1], reverse=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load text collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = utils.TextCollection(corpus_directory=\"./data/pantip/mobile/corpus\", tokenize_function=tokenize_func)\n",
    "# test_texts = utils.TextCollection(corpus_directory=\"./data/pantip/mobile/test_corpus\", tokenize_function=tokenize_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build word_index\n",
    "word_index = utils.build_word_index(texts, word2vec_vocab=w2v_vocab)\n",
    "len(word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build embedding_matrix\n",
    "embedding_matrix = utils.get_embedding_matrix(word2vec_model=w2v_model, word_index=word_index, fasttext=False)\n",
    "len(embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create tag_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bailarn.categorization import constant as categorization_constant\n",
    "from bailarn.categorization.categorization import Categorization\n",
    "\n",
    "categorization_tag_index = utils.build_tag_index(categorization_constant.TAG_LIST, categorization_constant.TAG_START_INDEX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = utils.build_input(texts,\n",
    "                       word_index,\n",
    "                       categorization_tag_index,\n",
    "                       categorization_constant.SEQUENCE_LENGTH,\n",
    "                       target='categorization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs.x[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs.y[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train new model without pre-train embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_categorization_model = Categorization(new_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_categorization_model.train(X_train=vs.x, y_train=vs.y,\n",
    "                               batch_size=100, validate_ratio=0.1,sensitive_learning=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_categorization_model.predict(vs.x[:1], decode_tag=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_categorization_model.predict(vs.x[:1], threshold_selection=0.1, decode_tag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scores = new_categorization_model.evaluate(vs.x, vs.y, threshold_selection=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = new_categorization_model.evaluate(vs.x, vs.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train new model with pre-train embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorization_model = Categorization(embedding_matrix=embedding_matrix, new_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show defined embedding weight\n",
    "# check if it equals the input embedding matrix\n",
    "categorization_model.model.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorization_model.train(X_train=vs.x, y_train=vs.y, batch_size=300, validate_ratio=0.2, sensitive_learning=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorization_model.predict(vs.x[:1], decode_tag=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorization_model.predict(vs.x[:1], threshold_selection=0.1, decode_tag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = categorization_model.evaluate(vs.x, vs.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorization_model.save(filepath=\"./bailarn/categorization/models/mock_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_categorization = Categorization(model_path=\"./bailarn/categorization/models/mock_model.h5\", new_model=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_categorization.model.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorization_model.model.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_categorization.predict(vs.x, decode_tag=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = loaded_categorization.evaluate(vs.x, vs.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Default model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "word_index = json.load(open('./bailarn/categorization/categorization_word_index.json'))\n",
    "embedding_matrix = utils.get_embedding_matrix(word2vec_model=w2v_model, word_index=word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load test texts from 100,000 pantip data (can be skipped)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load test texts from 100,000 pantip data\n",
    "# import pickle\n",
    "# texts = {}  # scores is an empty dict already\n",
    "# if os.path.getsize(\"texts_for_test.p\") > 0:\n",
    "#     with open(\"texts_for_test.p\", \"rb\") as f:\n",
    "#         unpickler = pickle.Unpickler(f)\n",
    "#         # if file is not empty scores will be equal\n",
    "#         # to the value unpickled\n",
    "#         texts = unpickler.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vs = utils.build_input(texts,\n",
    "#                        word_index,\n",
    "#                        categorization_tag_index,\n",
    "#                        categorization_constant.SEQUENCE_LENGTH,\n",
    "#                        target='categorization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorization = Categorization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding matrix is same shape but not same weights because of training process\n",
    "categorization.model.get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have trained\n",
    "categorization.model.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorization.predict(vs.x[:1], threshold_selection=0.1, decode_tag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = categorization.evaluate(vs.x, vs.y, threshold_selection=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = categorization.evaluate(vs.x, vs.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Others\n",
    "## - Create the best threshold selection manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bailarn.utils import utils\n",
    "# from bailarn.tokenizer import constant as tokenizer_constant\n",
    "# from bailarn.tokenizer.tokenizer import Tokenizer\n",
    "# from bailarn.word_embedder.word2vec import Word2Vec\n",
    "# from bailarn.categorization import constant as categorization_constant\n",
    "# from bailarn.categorization.categorization import Categorization\n",
    "# import pickle\n",
    "# import json\n",
    "# import numpy as np\n",
    "# import os\n",
    "# from sklearn.metrics import precision_recall_fscore_support\n",
    "# from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag_index = utils.build_tag_index(\n",
    "#     categorization_constant.TAG_LIST, categorization_constant.TAG_START_INDEX)\n",
    "# word_index = json.load(open('./bailarn/categorization/word_index_fasttext.json')) \n",
    "# len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# texts = {}  # scores is an empty dict already\n",
    "# if os.path.getsize(\"texts_for_test.p\") > 0:\n",
    "#     with open(\"texts_for_test.p\", \"rb\") as f:\n",
    "#         unpickler = pickle.Unpickler(f)\n",
    "#         # if file is not empty scores will be equal\n",
    "#         # to the value unpickled\n",
    "#         texts = unpickler.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vs = utils.build_input(texts,\n",
    "#                        word_index,\n",
    "#                        tag_index,\n",
    "#                        categorization_constant.SEQUENCE_LENGTH,\n",
    "#                        target='categorization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorization_model = Categorization(\n",
    "#     tag_index=tag_index, model_path=\"./bailarn/categorization/models/cnn_xmtc_fasttext_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = categorization_model.predict(vs.x, decode_tag=False)\n",
    "# y_pred[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold_selection_dict = dict((idx, []) for idx in range(\n",
    "#     len(categorization_constant.TAG_LIST)))\n",
    "# for class_idx in tqdm(range(len(categorization_constant.TAG_LIST))):\n",
    "#     label = categorization_constant.TAG_LIST[class_idx]\n",
    "#     for threshold in np.arange(0, 1.0, 0.005):\n",
    "\n",
    "#         y_pred_class = []\n",
    "#         for single_y_pred in y_pred:\n",
    "#             y_pred_class.append(single_y_pred[class_idx])\n",
    "#         y_pred_class = np.array(\n",
    "#             [pred >= threshold for pred in y_pred_class], dtype=np.bool_)\n",
    "\n",
    "#         y_true_class = []\n",
    "#         for single_y_true in vs.y:\n",
    "#             y_true_class.append(single_y_true[class_idx])\n",
    "#         y_true_class = np.array(y_true_class, dtype=np.bool_)\n",
    "#         _, _, f1_score, _ = precision_recall_fscore_support(\n",
    "#             y_true_class, y_pred_class, average='binary')\n",
    "\n",
    "#         threshold_selection_dict[class_idx].append(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold_selection_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Select max threshold\n",
    "# write_threshold_selection_dict = {}\n",
    "# for class_idx in range(len(categorization_constant.TAG_LIST)):\n",
    "#     max_idx = 0\n",
    "#     max_value = 0\n",
    "#     for idx, value in enumerate(threshold_selection_dict[class_idx]):\n",
    "#         if (value > max_value) & (idx != 0):\n",
    "#             max_idx = idx\n",
    "#             max_value = value\n",
    "#     write_threshold_selection_dict['class_{}'.format(class_idx)] = np.arange(0, 1.0, 0.005)[max_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_threshold_selection_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./cnn_xmtc_fasttext_threshold_selection.json', 'w', encoding='utf-8') as outfile:\n",
    "#     json.dump(write_threshold_selection_dict, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
