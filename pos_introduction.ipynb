{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liaok\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "C:\\Users\\liaok\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from bailarn.pos import POSTagger,constant\n",
    "from bailarn.utils import utils\n",
    "import deepcut\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Text File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read raw text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                      | 0/2 [00:00<?, ?it/s]\r",
      " 50%|███████████████               | 1/2 [00:07<00:07,  7.19s/it]\r",
      "100%|██████████████████████████████| 2/2 [00:09<00:00,  4.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish\n",
      "Corpus size : 2\n",
      "\n",
      "Example corpus text : เฒ่า/NN/O|วัย/NN/O|72/CD/MEA_B|ร้อง/VV/O|ถูก/AUX/O|รัฐ/NN/O|ยึด/VV/O|ที่/NN/O|ทำกิน/JJV/O|ที่/COMP/O|มี/VV/O|สค./NR/ABB_B|1/OD/O|-/PU/O|เป็น/VV/O|พื้นที่/NN/O|สาธารณะ/NN/O||1/OD/DTM_B| |กันยายน/NN/DTM_I| |2550/OD/DTM_I|10:42/OD/DTM_B|น./CL/DTM_I||พ่อ/NN/O|เฒ่า/NN/O|วัย/NN/O|72/CD/MEA_B|ร้องขอ/VV/O|ความ/FXN/O|เป็นธรรม/VA/O|ถูก/AUX/O|เจ้าหน้าที่/NN/O|รัฐ/NN/O|ยึด/VV/O|ที่ดิน/NN/O|ทำกิน/JJV/O|ที่/COMP/O|มี/VV/O|เอกสาร/NN/O|ส.ค./NN/TRM_B|1/OD/TRM_I| |และ/CNJ/O|เป็น/VV/O|ที่ดิน/NN/O|มรดก/NN/O|กว่า/AD\n",
      "\n",
      "Tokenized content : ['เฒ่า', '/', 'NN', '/', 'O', '|', 'วัย', '/NN/', 'O', '|', '72/CD/', 'MEA_B', '|', 'ร้อง', '/', 'VV', '/', 'O', '|', 'ถูก'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "texts = utils.TextCollection(corpus_directory=\"./data/BEST_mock/\", tokenize_function=deepcut.deepcut.tokenize)\n",
    "print(\"Corpus size : {}\\n\".format(texts.count))\n",
    "print(\"Example corpus text : {}\\n\".format(texts.get_content(0)[0:500]))\n",
    "print(\"Tokenized content : {} \\n\".format(texts.get_token_list(0)[0:20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read pre-tokenize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                      | 0/2 [00:00<?, ?it/s]\r",
      " 50%|███████████████               | 1/2 [00:00<00:00,  8.68it/s]\r",
      "100%|██████████████████████████████| 2/2 [00:00<00:00,  9.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish\n",
      "Corpus size : 2\n",
      "\n",
      "Example corpus text : เฒ่า/NN/O|วัย/NN/O|72/CD/MEA_B|ร้อง/VV/O|ถูก/AUX/O|รัฐ/NN/O|ยึด/VV/O|ที่/NN/O|ทำกิน/JJV/O|ที่/COMP/O|มี/VV/O|สค./NR/ABB_B|1/OD/O|-/PU/O|เป็น/VV/O|พื้นที่/NN/O|สาธารณะ/NN/O||1/OD/DTM_B| |กันยายน/NN/DTM_I| |2550/OD/DTM_I|10:42/OD/DTM_B|น./CL/DTM_I||พ่อ/NN/O|เฒ่า/NN/O|วัย/NN/O|72/CD/MEA_B|ร้องขอ/VV/O|ความ/FXN/O|เป็นธรรม/VA/O|ถูก/AUX/O|เจ้าหน้าที่/NN/O|รัฐ/NN/O|ยึด/VV/O|ที่ดิน/NN/O|ทำกิน/JJV/O|ที่/COMP/O|มี/VV/O|เอกสาร/NN/O|ส.ค./NN/TRM_B|1/OD/TRM_I| |และ/CNJ/O|เป็น/VV/O|ที่ดิน/NN/O|มรดก/NN/O|กว่า/AD\n",
      "\n",
      "Tokenized content : [['เฒ่า', 'NN', 'O'], ['วัย', 'NN', 'O'], ['72', 'CD', 'MEA_B'], ['ร้อง', 'VV', 'O'], ['ถูก', 'AUX', 'O'], ['รัฐ', 'NN', 'O'], ['ยึด', 'VV', 'O'], ['ที่', 'NN', 'O'], ['ทำกิน', 'JJV', 'O'], ['ที่', 'COMP', 'O'], ['มี', 'VV', 'O'], ['สค.', 'NR', 'ABB_B'], ['1', 'OD', 'O'], ['-', 'PU', 'O'], ['เป็น', 'VV', 'O'], ['พื้นที่', 'NN', 'O'], ['สาธารณะ', 'NN', 'O'], [' ', 'PU', 'O'], ['1', 'OD', 'DTM_B'], [' ', 'PU', 'O']] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "texts = utils.TextCollection(corpus_directory=\"./data/BEST_mock//\", word_delimiter=\"|\",tag_delimiter=\"/\")\n",
    "print(\"Corpus size : {}\\n\".format(texts.count))\n",
    "print(\"Example corpus text : {}\\n\".format(texts.get_content(0)[0:500]))\n",
    "print(\"Tokenized content : {} \\n\".format(texts.get_token_list(0)[0:20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Word Indexer from vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load words from text collection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                      | 0/2 [00:00<?, ?it/s]\r",
      "100%|█████████████████████████████| 2/2 [00:00<00:00, 665.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish\n"
     ]
    }
   ],
   "source": [
    "word_index = utils.build_word_index(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load saved word index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./bailarn/pos/pos_word_index.json', 'r') as f:\n",
    "    word_index = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<PAD>': 0,\n",
       " 'ADV': 16,\n",
       " 'AUX': 13,\n",
       " 'CD': 20,\n",
       " 'CL': 19,\n",
       " 'CNJ': 27,\n",
       " 'COMP': 26,\n",
       " 'DDEM': 8,\n",
       " 'DINT': 7,\n",
       " 'DPER': 6,\n",
       " 'FWA': 33,\n",
       " 'FWN': 31,\n",
       " 'FWV': 32,\n",
       " 'FWX': 34,\n",
       " 'FXAJ': 25,\n",
       " 'FXAV': 24,\n",
       " 'FXG': 23,\n",
       " 'FXN': 22,\n",
       " 'IJ': 29,\n",
       " 'JJA': 14,\n",
       " 'JJV': 15,\n",
       " 'NEG': 17,\n",
       " 'NN': 1,\n",
       " 'NR': 2,\n",
       " 'OD': 21,\n",
       " 'P': 28,\n",
       " 'PAR': 18,\n",
       " 'PDEM': 5,\n",
       " 'PDT': 9,\n",
       " 'PINT': 4,\n",
       " 'PPER': 3,\n",
       " 'PU': 30,\n",
       " 'REFX': 10,\n",
       " 'VA': 12,\n",
       " 'VV': 11}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_index = utils.build_tag_index(constant.TAG_LIST, start_index=1)\n",
    "tag_index['<PAD>'] = 0\n",
    "tag_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform text into input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start building input...\n",
      "Start generating x y...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                      | 0/2 [00:00<?, ?it/s]\r",
      "100%|█████████████████████████████| 2/2 [00:00<00:00, 330.96it/s]\n"
     ]
    }
   ],
   "source": [
    "vs = utils.build_input(text_collection=texts, \n",
    "                       word_index=word_index, \n",
    "                       tag_index=tag_index, \n",
    "                       sequence_length=constant.SEQUENCE_LENGTH, \n",
    "                       target=\"pos\", \n",
    "                       for_train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([27190, 50884, 20327, 19012, 35041, 43449, 26772, 34424, 53518,\n",
       "       34424, 29195, 10020, 50546, 47142, 27200, 22529, 33569, 50546,\n",
       "       46763, 21654,  6248,  3444, 31031, 27190, 50884, 20327,  1205,\n",
       "       31619,  5821, 35041, 54422, 43449, 26772, 12068, 53518, 34424,\n",
       "       29195, 51291,  1069, 50546, 41633, 27200, 12068,   197, 10203,\n",
       "       14666, 25824, 53884, 53518, 38214, 53981, 51051, 31031, 27951,\n",
       "       43449, 42297, 18812, 10934,  1073,  1934])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs.x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1],\n",
       "       [ 1],\n",
       "       [20],\n",
       "       [11],\n",
       "       [13],\n",
       "       [ 1],\n",
       "       [11],\n",
       "       [ 1],\n",
       "       [15],\n",
       "       [26],\n",
       "       [11],\n",
       "       [ 2],\n",
       "       [21],\n",
       "       [30],\n",
       "       [11],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [21],\n",
       "       [ 1],\n",
       "       [21],\n",
       "       [21],\n",
       "       [19],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [20],\n",
       "       [11],\n",
       "       [22],\n",
       "       [12],\n",
       "       [13],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [11],\n",
       "       [ 1],\n",
       "       [15],\n",
       "       [26],\n",
       "       [11],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [21],\n",
       "       [27],\n",
       "       [11],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [16],\n",
       "       [20],\n",
       "       [19],\n",
       "       [11],\n",
       "       [11],\n",
       "       [11],\n",
       "       [28],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [11],\n",
       "       [ 1],\n",
       "       [11],\n",
       "       [ 1],\n",
       "       [11],\n",
       "       [11],\n",
       "       [11]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs.y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NN',\n",
       " 'NN',\n",
       " 'CD',\n",
       " 'VV',\n",
       " 'AUX',\n",
       " 'NN',\n",
       " 'VV',\n",
       " 'NN',\n",
       " 'JJV',\n",
       " 'COMP',\n",
       " 'VV',\n",
       " 'NR',\n",
       " 'OD',\n",
       " 'PU',\n",
       " 'VV',\n",
       " 'NN',\n",
       " 'NN',\n",
       " 'OD',\n",
       " 'NN',\n",
       " 'OD',\n",
       " 'OD',\n",
       " 'CL',\n",
       " 'NN',\n",
       " 'NN',\n",
       " 'NN',\n",
       " 'CD',\n",
       " 'VV',\n",
       " 'FXN',\n",
       " 'VA',\n",
       " 'AUX',\n",
       " 'NN',\n",
       " 'NN',\n",
       " 'VV',\n",
       " 'NN',\n",
       " 'JJV',\n",
       " 'COMP',\n",
       " 'VV',\n",
       " 'NN',\n",
       " 'NN',\n",
       " 'OD',\n",
       " 'CNJ',\n",
       " 'VV',\n",
       " 'NN',\n",
       " 'NN',\n",
       " 'ADV',\n",
       " 'CD',\n",
       " 'CL',\n",
       " 'VV',\n",
       " 'VV',\n",
       " 'VV',\n",
       " 'P',\n",
       " 'NN',\n",
       " 'NN',\n",
       " 'VV',\n",
       " 'NN',\n",
       " 'VV',\n",
       " 'NN',\n",
       " 'VV',\n",
       " 'VV',\n",
       " 'VV']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs.readable_y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train new model without pre-train embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 300)         16713000  \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, None, 436)         905136    \n",
      "_________________________________________________________________\n",
      "crf_1 (CRF)                  (None, None, 35)          16590     \n",
      "=================================================================\n",
      "Total params: 17,634,726\n",
      "Trainable params: 17,634,726\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Default embedding_matrix = None\n",
    "new_pos_model = POSTagger(new_model=True,tag_index=tag_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 300)         16713000  \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, None, 436)         905136    \n",
      "_________________________________________________________________\n",
      "crf_1 (CRF)                  (None, None, 35)          16590     \n",
      "=================================================================\n",
      "Total params: 17,634,726\n",
      "Trainable params: 17,634,726\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 23 samples, validate on 3 samples\n",
      "Epoch 1/3\n",
      "\r",
      "23/23 [==============================] - 1s 62ms/step - loss: 4.3177 - acc: 0.0429 - val_loss: 3.6096 - val_acc: 0.0565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liaok\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\liaok\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "| f1_macro: 0.0583 || f1_micro: 0.0722 || precision: 0.0556 || recall: 0.1053 |\n",
      "\n",
      "Epoch 2/3\n",
      "\r",
      "23/23 [==============================] - 1s 53ms/step - loss: 4.2962 - acc: 0.0429 - val_loss: 3.5864 - val_acc: 0.0565\n",
      "\r",
      "| f1_macro: 0.0583 || f1_micro: 0.0722 || precision: 0.0556 || recall: 0.1053 |\n",
      "\n",
      "Epoch 3/3\n",
      "\r",
      "23/23 [==============================] - 1s 44ms/step - loss: 4.2713 - acc: 0.0429 - val_loss: 3.5550 - val_acc: 0.2034\n",
      "\r",
      "| f1_macro: 0.0799 || f1_micro: 0.2167 || precision: 0.0710 || recall: 0.1129 |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_pos_model.train(vs.x,vs.y,epochs=3,train_name='new-model-without-pre-train-embedding-matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = new_pos_model.predict(vs.x, decode_tag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['NN', 'NN', 'NN', ..., 'NN', 'NN', 'NN'],\n",
       "       ['NN', 'NN', 'NN', ..., 'NN', 'NN', 'NN'],\n",
       "       ['NN', 'NN', 'NN', ..., 'NN', 'NN', 'NN'],\n",
       "       ...,\n",
       "       ['COMP', 'COMP', 'COMP', ..., 'COMP', 'COMP', 'COMP'],\n",
       "       ['NN', 'NN', 'NN', ..., 'NN', 'NN', 'NN'],\n",
       "       ['NN', 'NN', 'NN', ..., '<PAD>', '<PAD>', '<PAD>']], dtype='<U5')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liaok\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\liaok\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('f1_macro', 0.05708821278969632),\n",
       "             ('f1_micro', 0.2903846153846154),\n",
       "             ('precision', 0.05039658514348556),\n",
       "             ('recall', 0.07788144309693044)])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_pos_model.evaluate(vs.x,vs.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train new model with pre-train embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bailarn.word_embedder.word2vec import Word2Vec\n",
    "w2v_model = Word2Vec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                  | 0/55709 [00:00<?, ?it/s]\r",
      " 10%|█▉                  | 5326/55709 [00:00<00:00, 52299.18it/s]\r",
      " 22%|████               | 11978/55709 [00:00<00:00, 59253.00it/s]\r",
      " 34%|██████▍            | 18967/55709 [00:00<00:00, 62727.13it/s]\r",
      " 45%|████████▌          | 25184/55709 [00:00<00:00, 62546.80it/s]\r",
      " 60%|███████████▎       | 33331/55709 [00:00<00:00, 64607.52it/s]\r",
      " 73%|█████████████▉     | 40696/55709 [00:00<00:00, 65783.60it/s]\r",
      " 87%|████████████████▌  | 48696/55709 [00:00<00:00, 66337.42it/s]\r",
      "100%|███████████████████| 55709/55709 [00:00<00:00, 67999.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# word_index = json.load(open('./bailarn/categorization/word_index.json'))\n",
    "embedding_matrix = utils.get_embedding_matrix(word2vec_model=w2v_model, word_index=word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 300)         16712700  \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, None, 436)         905136    \n",
      "_________________________________________________________________\n",
      "crf_2 (CRF)                  (None, None, 35)          16590     \n",
      "=================================================================\n",
      "Total params: 17,634,426\n",
      "Trainable params: 17,634,426\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = POSTagger(embedding_matrix=embedding_matrix, new_model=True,tag_index=tag_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 300)         16712700  \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, None, 436)         905136    \n",
      "_________________________________________________________________\n",
      "crf_2 (CRF)                  (None, None, 35)          16590     \n",
      "=================================================================\n",
      "Total params: 17,634,426\n",
      "Trainable params: 17,634,426\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "\r",
      "26/26 [==============================] - 1s 49ms/step - loss: 4.1849 - acc: 0.0239\n",
      "Epoch 2/3\n",
      "\r",
      "26/26 [==============================] - 1s 42ms/step - loss: 3.7457 - acc: 0.2787\n",
      "Epoch 3/3\n",
      "\r",
      "26/26 [==============================] - 1s 45ms/step - loss: 3.4002 - acc: 0.2814\n"
     ]
    }
   ],
   "source": [
    "model.train(vs.x, vs.y, epochs=3,train_name='model-with-pretrain',validation_split=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liaok\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\liaok\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('f1_macro', 0.05944112495409216),\n",
       "             ('f1_micro', 0.3153846153846154),\n",
       "             ('precision', 0.0628309520151585),\n",
       "             ('recall', 0.07717410990239734)])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(vs.x, vs.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 300)         16712700  \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, None, 436)         905136    \n",
      "_________________________________________________________________\n",
      "crf_2 (CRF)                  (None, None, 35)          16590     \n",
      "=================================================================\n",
      "Total params: 17,634,426\n",
      "Trainable params: 17,634,426\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('ab55c.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use pre-trained model\n",
    "- process on pantip data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 60, 5)             380       \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 60, 512)           536576    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 60, 512)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 60, 512)           1574912   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 60, 512)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 60, 256)           656384    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 60, 256)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 60, 36)            9252      \n",
      "=================================================================\n",
      "Total params: 2,777,504\n",
      "Trainable params: 2,777,504\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liaok\\Anaconda3\\lib\\site-packages\\keras\\models.py:291: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ฉัน', 'กิน', 'ข้าว']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bailarn.tokenizer import constant as tokenizer_constant\n",
    "from bailarn.tokenizer.tokenizer import Tokenizer\n",
    "\n",
    "# Create index for character and tag\n",
    "char_index = utils.build_tag_index(tokenizer_constant.CHARACTER_LIST, tokenizer_constant.CHAR_START_INDEX)\n",
    "tag_index = utils.build_tag_index(tokenizer_constant.TAG_LIST, tokenizer_constant.TAG_START_INDEX)\n",
    "\n",
    "tokenizer_model = Tokenizer(char_index, tag_index)\n",
    "\n",
    "def tokenize_func(sentence):\n",
    "    return tokenizer_model.predict(sentence)\n",
    "tokenize_func(\"ฉันกินข้าว\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "word_index = json.load(open('./bailarn/pos/pos_word_index.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_index = utils.build_tag_index(constant.TAG_LIST, start_index=constant.TAG_START_INDEX)\n",
    "tag_index[\"<PAD>\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                      | 0/1 [00:00<?, ?it/s]\r",
      "100%|██████████████████████████████| 1/1 [00:00<00:00,  6.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish\n"
     ]
    }
   ],
   "source": [
    "texts = utils.TextCollection(\"/\", tokenize_function=tokenize_func)\n",
    "texts.add_text(\"แจ้งเตือนดีลลวงโลกของNasambkและshopeeต้องอ่านเพื่อไม่เป็นเหยื่ออัพเดตทางshopeeติดต่อมาครับส่วนระบบใครจะถูกผิดผมไม่ทราบได้สิ่งที่ควรทำคือปรับปรุงแก้ไขไม่ว่าจะทางร้านหรือทางShopeeโดยทางshopeeออกโค้ดส่วนลดให้ใหม่และผมได้เครื่องเรียบร้อยขอบคุณการแก้ไขของshopeeส่วนร้านก็อยากให้ปรับปรุงเพราะผมยังคงกังขาทุกอย่างมันดูแปลกๆแจ้งเตือนดีลของร้านNASAmbkในshopeeตามที่ผมคาดการณ์ไว้ยื้อการส่งของจนหมดเวลาระบบshopeeจะยกเลิกออเดอร์อัตโนมัติผมกดขยายเวลาจัดส่งก็ไม่ช่วยอะไรเพราะทางร้านต้นทางไม่กดยอมรับผมได้สั่งซื้อMate00proที่เป็นdealoftheday00,000บาทในวันที่00กพ.ระบบแจ้งให้ส่งของภายในวันที่00กพ.ปรากฎว่าร้านยื้อไม่ส่งของอ้างสารพัดจนหมดเวลาส่งระบบshopeeจึงทำการยกเลิกออเดอร์อัตโนมัติไม่ได้ของในราคานั้นมันคือขบวนการหลอกลวงต้มตุ๋นนั่นเองดูรายละเอียดในภาพนะครับช่วงแรกคุยกับร้านอีกช่วงคุยกับshopeeแก้ไขข้อความเมื่อ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start building input...\n",
      "Start generating x...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                      | 0/2 [00:00<?, ?it/s]\r",
      "100%|██████████████████████████████████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "vs = utils.build_input(text_collection=texts,\n",
    "                        word_index=word_index,\n",
    "                        tag_index=tag_index,\n",
    "                        sequence_length=constant.SEQUENCE_LENGTH, # padding size\n",
    "                        target='pos', for_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13405, 45715, 30665, 55707,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0],\n",
       "       [  906, 27280, 45604, 46842,  6332,    39, 55707, 41633, 55707,\n",
       "        10556, 45064, 42205, 26137, 27200, 39358, 55707, 10442, 55707,\n",
       "        10193, 38214, 47807, 38790, 33198, 22069, 53474, 35041,   169,\n",
       "        16195, 26137, 52081, 39396, 39552, 34424,  8912, 37956, 35471,\n",
       "        44900, 15567, 11956, 53474, 10442, 16455, 11485, 10442, 55707,\n",
       "        47913, 10442, 55707, 32056, 10353, 38790, 15948, 41248, 32444,\n",
       "        41633, 16195, 39396, 42988, 26577, 18444],\n",
       "       [49636, 15567,    39, 55707, 38790, 16455, 33351, 27961, 41248,\n",
       "        44900, 40708, 16195, 52620, 54717,   419, 40401, 13531, 26704,\n",
       "        45204,  1113,   906, 27280, 45604,    39, 16455, 55707, 11983,\n",
       "        55707, 21938, 34424, 16195, 25052,  9938, 20739, 54436, 49636,\n",
       "        46974,    39, 13160, 20618, 16659, 33198, 55707, 53474, 43051,\n",
       "        46404, 55707, 55707, 16195, 23081, 19612, 16659, 27332, 46974,\n",
       "        33351, 26137, 37241, 12814, 40708, 10442],\n",
       "       [16455,  1882, 10442, 26137, 23081,  9804, 47489, 16195, 39396,\n",
       "        47963, 26810, 55707, 55707, 34424, 27200, 55707, 55707, 50939,\n",
       "        11983, 25371, 34424, 55707, 50250, 33198,   906, 41248, 46974,\n",
       "           39, 21929, 11983, 25371, 34424, 55707, 50250, 55707, 53486,\n",
       "        16455, 54436, 26137, 46974,    39, 52662, 24120, 13160, 20618,\n",
       "        16659, 46974, 33198, 55707,  7045, 37956, 49636, 43051, 46404,\n",
       "         8810, 26137, 39396,    39, 11983, 14342],\n",
       "       [40634, 13531, 35471,  6315, 19089, 31462,  5191, 44352, 26704,\n",
       "        29214, 11983, 50616,  1407, 47807, 53221, 26698, 26117, 36325,\n",
       "        16455, 21251, 53221, 26117, 36325, 55707, 32020,   733,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vs.readable_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 300)         16712700  \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, None, 436)         905136    \n",
      "_________________________________________________________________\n",
      "crf_1 (CRF)                  (None, None, 35)          16590     \n",
      "=================================================================\n",
      "Total params: 17,634,426\n",
      "Trainable params: 17,634,426\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimension 0 in both shapes must be equal, but are 55709 and 55710 for 'Assign_21' (op: 'Assign') with input shapes: [55709,300], [55710,300].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m             Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[0;32m    670\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 671\u001b[1;33m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[0;32m    672\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Dimension 0 in both shapes must be equal, but are 55709 and 55710 for 'Assign_21' (op: 'Assign') with input shapes: [55709,300], [55710,300].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-2ed76337510e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPOSTagger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtag_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\Thai_NLP_platform\\bailarn\\pos\\pos_tagger.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model_path, new_model, tag_index, embedding_matrix)\u001b[0m\n\u001b[0;32m     39\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDEFULT_MODEL_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"DEFULT_MODEL_PATH does not exist\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDEFULT_MODEL_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Thai_NLP_platform\\bailarn\\pos\\model.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(model_path)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mkeras_contrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msave_load_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m     \u001b[0msave_load_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_all_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minclude_optimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras_contrib-2.0.8-py3.6.egg\\keras_contrib\\utils\\save_load_utils.py\u001b[0m in \u001b[0;36mload_all_weights\u001b[1;34m(model, filepath, include_optimizer)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;31m# set weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         \u001b[0mtopology\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model_weights'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[1;31m# Set optimizer weights.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minclude_optimizer\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m'optimizer_weights'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'optimizer'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[1;34m(f, layers, reshape)\u001b[0m\n\u001b[0;32m   3380\u001b[0m                              ' elements.')\n\u001b[0;32m   3381\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3382\u001b[1;33m     \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[1;34m(tuples)\u001b[0m\n\u001b[0;32m   2366\u001b[0m                 assign_placeholder = tf.placeholder(tf_dtype,\n\u001b[0;32m   2367\u001b[0m                                                     shape=value.shape)\n\u001b[1;32m-> 2368\u001b[1;33m                 \u001b[0massign_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2369\u001b[0m                 \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assign_placeholder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0massign_placeholder\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2370\u001b[0m                 \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assign_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0massign_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36massign\u001b[1;34m(self, value, use_locking)\u001b[0m\n\u001b[0;32m    514\u001b[0m       \u001b[0mthe\u001b[0m \u001b[0massignment\u001b[0m \u001b[0mhas\u001b[0m \u001b[0mcompleted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m     \"\"\"\n\u001b[1;32m--> 516\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mstate_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0massign_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\state_ops.py\u001b[0m in \u001b[0;36massign\u001b[1;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[0;32m    269\u001b[0m     return gen_state_ops.assign(\n\u001b[0;32m    270\u001b[0m         \u001b[0mref\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m         validate_shape=validate_shape)\n\u001b[0m\u001b[0;32m    272\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_state_ops.py\u001b[0m in \u001b[0;36massign\u001b[1;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[0;32m     43\u001b[0m   result = _op_def_lib.apply_op(\"Assign\", ref=ref, value=value,\n\u001b[0;32m     44\u001b[0m                                 \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m                                 use_locking=use_locking, name=name)\n\u001b[0m\u001b[0;32m     46\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    765\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    766\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 767\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    768\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   2506\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[0;32m   2507\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2508\u001b[1;33m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2509\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2510\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   1871\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1872\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1873\u001b[1;33m   \u001b[0mshapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1874\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1875\u001b[0m     raise RuntimeError(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   1821\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[0;32m    608\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[0;32m    609\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m                                   debug_python_shape_fn, require_shape_fn)\n\u001b[0m\u001b[0;32m    611\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m       \u001b[1;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, debug_python_shape_fn, require_shape_fn)\u001b[0m\n\u001b[0;32m    674\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Dimension 0 in both shapes must be equal, but are 55709 and 55710 for 'Assign_21' (op: 'Assign') with input shapes: [55709,300], [55710,300]."
     ]
    }
   ],
   "source": [
    "model = POSTagger(tag_index=tag_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(texts.get_token_list(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(vs.x).flatten()[:len(texts.get_token_list(0))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pre-train model (edit the value in constant.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = POSTagger(model_path = \"abc.h5\",tag_index=tag_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.predict(vs.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.predict(vs.x, decode_tag=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
